{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMo9IEd/kDkT7E9LSD/ay5R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahsan97Javed/gtfs-batch-pipeline/blob/main/output_gtfs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GTFS Batch Processing Pipeline â€” Output Microservice\n",
        "\n",
        "## 1. Mount Google Drive & Set Paths\n"
      ],
      "metadata": {
        "id": "6zQzRJBwEryY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3waJ0lAWEZo7",
        "outputId": "6b011b53-b2cd-443f-f19b-b03ae6a46255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "agg_path = '/content/drive/My Drive/GTFS_AGGREGATED'\n",
        "# Outputs will remain here and can be copied elsewhere if needed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. List All Aggregated Output Files\n"
      ],
      "metadata": {
        "id": "z_W2N99WEwzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_files = os.listdir(agg_path)\n",
        "print(\"Aggregated outputs available:\")\n",
        "for f in output_files:\n",
        "    print(f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hESUStemEvL5",
        "outputId": "7424e4b1-62cd-44de-80d5-809827b5c144"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated outputs available:\n",
            "trip_counts_per_route.csv\n",
            "popular_stops.csv\n",
            "trips_per_day.csv\n",
            "avg_stops_per_trip.txt\n",
            "routes_per_agency.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Load and Summarize Key Aggregated Results\n",
        "\n"
      ],
      "metadata": {
        "id": "lht3V1NDE4by"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for fname in output_files:\n",
        "    if fname.endswith('.csv'):\n",
        "        print(f\"\\n===== {fname} =====\")\n",
        "        df = pd.read_csv(os.path.join(agg_path, fname))\n",
        "        print(df.head())\n",
        "        print(f\"(Rows: {df.shape[0]}, Columns: {df.shape[1]})\")\n",
        "    elif fname.endswith('.txt'):\n",
        "        print(f\"\\n===== {fname} =====\")\n",
        "        with open(os.path.join(agg_path, fname), 'r') as f:\n",
        "            print(f.read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44ce5_ZnE7QJ",
        "outputId": "20901ffc-cd31-478a-900d-d1d49bed48e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== trip_counts_per_route.csv =====\n",
            "   route_id  trip_count route_short_name\n",
            "0     18162        2617               U5\n",
            "1      6386        2454               M8\n",
            "2      8443        2329              AST\n",
            "3     24376        2133              302\n",
            "4     10748        2054               18\n",
            "(Rows: 25081, Columns: 3)\n",
            "\n",
            "===== popular_stops.csv =====\n",
            "   stop_id  num_stop_times             stop_name\n",
            "0   172476            6624    Hamburg Bf. Altona\n",
            "1   390511            5623            Hertzallee\n",
            "2   449492            4515  F Willy-Brandt-Platz\n",
            "3   252245            3906    F Eschenheimer Tor\n",
            "4   175628            3906     F Schweizer Platz\n",
            "(Rows: 429051, Columns: 3)\n",
            "\n",
            "===== trips_per_day.csv =====\n",
            "  day_of_week  num_trips\n",
            "0      monday     982723\n",
            "1     tuesday     984563\n",
            "2   wednesday     969625\n",
            "3    thursday     929649\n",
            "4      friday     965953\n",
            "(Rows: 7, Columns: 2)\n",
            "\n",
            "===== avg_stops_per_trip.txt =====\n",
            "Average stops per trip: 20.36\n",
            "\n",
            "===== routes_per_agency.csv =====\n",
            "   agency_id  num_routes                   agency_name\n",
            "0        359        1006  Verkehrsverbund Rhein-Neckar\n",
            "1          7         814     Hamburger Verkehrsverbund\n",
            "2        194         804                       VGM/VRL\n",
            "3        263         700     Verkehrsverbund Stuttgart\n",
            "4        270         614   Verkehrsverbund Rhein-Mosel\n",
            "(Rows: 451, Columns: 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Upload Key Aggregates to Google BigQuery"
      ],
      "metadata": {
        "id": "DQ2CuYEYFD7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and import BigQuery client\n",
        "!pip install --quiet google-cloud-bigquery\n",
        "from google.cloud import bigquery\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "project_id = \"gtfs-batch-pipeline\"\n",
        "\n",
        "# Define a BigQuery dataset (will be created if not exists)\n",
        "dataset_id = f\"{project_id}.gtfs_batch\"\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "# Create the dataset\n",
        "def create_dataset_if_not_exists(dataset_id):\n",
        "    try:\n",
        "        client.get_dataset(dataset_id)\n",
        "        print(f\"Dataset {dataset_id} already exists.\")\n",
        "    except Exception:\n",
        "        dataset = bigquery.Dataset(dataset_id)\n",
        "        dataset.location = \"EU\"\n",
        "        dataset = client.create_dataset(dataset, exists_ok=True)\n",
        "        print(f\"Created dataset {dataset_id}.\")\n",
        "\n",
        "create_dataset_if_not_exists(dataset_id)\n",
        "\n",
        "# List of main result files to upload\n",
        "files_to_upload = [\n",
        "    \"trip_counts_per_route.csv\",\n",
        "    \"popular_stops.csv\",\n",
        "    \"trips_per_day.csv\",\n",
        "    \"routes_per_agency.csv\"\n",
        "]\n",
        "for fname in files_to_upload:\n",
        "    csv_path = os.path.join(agg_path, fname)\n",
        "    if os.path.exists(csv_path):\n",
        "        table_id = f\"{dataset_id}.{fname.replace('.csv','')}\"\n",
        "        job_config = bigquery.LoadJobConfig(\n",
        "            autodetect=True, skip_leading_rows=1, source_format=bigquery.SourceFormat.CSV\n",
        "        )\n",
        "        with open(csv_path, \"rb\") as source_file:\n",
        "            job = client.load_table_from_file(source_file, table_id, job_config=job_config)\n",
        "        job.result()\n",
        "        print(f\"Uploaded {fname} to BigQuery as {table_id}.\")\n",
        "    else:\n",
        "        print(f\"{fname} not found, skipping.\")\n",
        "\n",
        "# verify upload\n",
        "for fname in files_to_upload:\n",
        "    table_id = f\"{dataset_id}.{fname.replace('.csv','')}\"\n",
        "    try:\n",
        "        table = client.get_table(table_id)\n",
        "        print(f\"{table_id}: {table.num_rows} rows uploaded.\")\n",
        "    except Exception as e:\n",
        "        print(f\"{table_id} not found or error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjkodW8wFF4q",
        "outputId": "e0b646ca-a2ba-40af-adaa-50941734a7de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dataset gtfs-batch-pipeline.gtfs_batch.\n",
            "Uploaded trip_counts_per_route.csv to BigQuery as gtfs-batch-pipeline.gtfs_batch.trip_counts_per_route.\n",
            "Uploaded popular_stops.csv to BigQuery as gtfs-batch-pipeline.gtfs_batch.popular_stops.\n",
            "Uploaded trips_per_day.csv to BigQuery as gtfs-batch-pipeline.gtfs_batch.trips_per_day.\n",
            "Uploaded routes_per_agency.csv to BigQuery as gtfs-batch-pipeline.gtfs_batch.routes_per_agency.\n",
            "gtfs-batch-pipeline.gtfs_batch.trip_counts_per_route: 25081 rows uploaded.\n",
            "gtfs-batch-pipeline.gtfs_batch.popular_stops: 429051 rows uploaded.\n",
            "gtfs-batch-pipeline.gtfs_batch.trips_per_day: 7 rows uploaded.\n",
            "gtfs-batch-pipeline.gtfs_batch.routes_per_agency: 451 rows uploaded.\n"
          ]
        }
      ]
    }
  ]
}